<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Ivan  Puhachov | Vector GAN</title>
<meta name="description" content="My personal webpage and log. Working on my PhD in CS at computer graphics lab. Process sketches and line drawings to make fine art. Research activities here - computer graphics, applied geometry, image processing.">

<!-- Open Graph -->

<meta property="og:site_name" content="ivan's work" />
<meta property="og:type" content="object" />
<meta property="og:title" content="Vector GAN" />
<meta property="og:url" content="https://puhachov.xyz/projects/vector_gan/" />
<meta property="og:description" content="Training GAN to generate vector images." />
<meta property="og:image" content="https://puhachov.xyz/assets/img/vector_gan/preview.png" />


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üçø</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/projects/vector_gan/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Vector GAN",
      "description": "Training GAN to generate vector images.",
      "published": "May 15, 2021",
      "authors": [
        
        {
          "author": "Ivan Puhachov",
          "authorURL": "https://puhachov.xyz",
          "affiliations": [
            {
              "name": "UdeM, Canada",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Ivan</span>   Puhachov
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>Vector GAN</h1>
        <p>Training GAN to generate vector images.</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <h3 id="tldr">TLDR</h3>

<p>We trained and evaluated several GAN models in a field of vector image generation. The model outputs parameters for a fixed set of drawing primitives (curves and circles), contrary to common ‚Äúraster‚Äù GAN, which generate fixed size image. Despite being trained with 64x64 px image dataset, such model can generate sketches at any resolution, due to using vector graphics.</p>

<p>To achieve this we use differentiable rasterizer from <d-cite key="diffsvg"></d-cite> and train different architectures with various datasets.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/vector_gan/my_plot_raster.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
    Typical GAN generates raster image of a fixed resolution. 
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/vector_gan/my_plot_vector.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
    Our GAN generates vector graphics, which can be viewed at any resolution and edited easily without loss of quality.
</div>

<blockquote>
  <p><strong>Disclaimer</strong>: This is a project I did for <a href="https://gauthiergidel.github.io/courses/game_theory_ML_2021.html">IFT 6756: Game Theory and ML</a></p>
</blockquote>

<h3 id="motivation">Motivation</h3>

<p>Vector graphics allows for editing without loss of quality. It stores images as a collection of primitives (lines, bezier curves, circles, etc.) with corresponding control parameters (color, width, control points).</p>

<p>Typical generative models are trained on raster images (image as array), while vector graphics space is non-euclidean and thus more challenging. Several approaches were tried, until finally a differentiable rasterizer proposed in <d-cite key="diffsvg"></d-cite> made it possible to do a direct backpropagation to primitives parameters.</p>

<p>In this project we apply differentiable rasterizer from <d-cite key="diffsvg"></d-cite> to experiment with generative art on different datasets, GAN architectures, and create adversarial examples using painting. We show that it may become a nice tool in media art creation, as it connects capable GANs and other neural nets with all the advantages of vector graphics.</p>

<p><strong>Transparency</strong>: the referenced paper <d-cite key="diffsvg"></d-cite> already provides the examples of GAN model trained using their rasterizer. The aim of this project was to reproduce their result independently, try another application and new data.</p>

<div class="l-gutter">
  <img class="img-fluid " src="/assets/img/vector_gan/diffsvg.png" data-zoomable="" />
</div>

<h3 id="related-work">Related work</h3>

<p>Most generative adversarial networks are generating raster images. DoodlerGAN <d-cite key="doodlergan"></d-cite> aimed to replicate human drawings by generating raster body parts.</p>

<p>SketchRNN <d-cite key="sketchrnn"></d-cite> modeled drawing as a decision making sequential process and trained seq2seq RNN VAE to generate quick sketches. SVG VAE <d-cite key="svgvae"></d-cite> applies the same approach to model fonts as a sequence of 4 commands, SketchBERT <d-cite key="sketchbert"></d-cite> moved to a next level by training a giant BERT model on the same data. DeepSVG <d-cite key="carlier2020deepsvg"></d-cite> uses transformers to generate SVG control commands for a vider family of svg primitives.</p>

<p>Differentiable rasterizer proposed in <d-cite key="diffsvg"></d-cite> allows gradient flow from rendered image to svg parameteres, thus we can optimize svg primitives directly from raster signal. They also showed several application of generative models. Im2Vec <d-cite key="reddy2021im2vec"></d-cite> uses this rasterizer to generate vector graphics from raster examples.</p>

<h2 id="experiments">Experiments</h2>

<h4 id="dataset">Dataset</h4>
<p>We took simple sketches from QuickDraw dataset with categories <code class="language-plaintext highlighter-rouge">apple</code>, <code class="language-plaintext highlighter-rouge">cookie</code>, <code class="language-plaintext highlighter-rouge">donut</code>, <code class="language-plaintext highlighter-rouge">face</code>, <code class="language-plaintext highlighter-rouge">lollipop</code> and 5000 of each category with resolution 64x64. Note that we train a ‚Äúgrayscale‚Äù model to save computations and fit to grayscale dataset, while it is possible to have colored sketches.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/vector_gan/data.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
    Dataset examples from QuickDraw data.
</div>

<p>We also tried training on more complex classes like <code class="language-plaintext highlighter-rouge">owl</code> or another dataset Creative Birds, but due to computational limitations our model did not converge to any good looking results.</p>

<h4 id="gan-architectures">GAN architectures</h4>
<p>Generator takes as input a latent vector $z \in \mathbb{R}^{100}$ and outputs parameters for 16 bezier curves (14 positional parameters + width and alpha) and 5 circles (2 positional parameters + radius + width + alpha). Neural net consists of 4 flat linear layers of dimensions [128, 256, 512, 1024], the last layer is then projected into each parameter family independently. Output parameters is then grouped and passed to differentiable rasterizer to generate image.</p>

<p>Discriminator is a convolutional neural network of 6 layers, with LeakyReLU activation. After experiments we ended up using the same discriminator architecture as was proposed in the original paper, as our attempts failed due to discriminator net being too powerful.</p>

<p>We implemented and trained the following modifications for training GAN, commonly used in literature.</p>

<p>Training of each model took approximately <strong>10 hours</strong> on a single GPU (NVidia RTX2080Ti). Unfortunately, we could not use Google Colab as differentiable rasterizer was not compatible with Colab hardware. Number of experiments was also limited due to high computational costs.</p>

<ul>
  <li><strong>WGAN</strong> <d-cite key="arjovsky2017wasserstein"></d-cite> makes a critic $K$-Lipschitz by clipping its gradients to stabilize training</li>
</ul>

\[\omega \leftarrow clip (\omega, -0.01, 0.01)\]

<ul>
  <li><strong>WGAN-GP</strong> <d-cite key="gulrajani2017improved"></d-cite> forces $K$-Lipschitz by adding a gradient penalty to the loss</li>
</ul>

\[\hat x \leftarrow \epsilon x_{real} + (1-\epsilon) x_{fake}\]

\[loss \leftarrow D(x_{fake}) - D(x_{real}) + \lambda (\| \nabla_{\hat x} D(\hat x) \|_2 - 1)^2\]

<ul>
  <li><strong>SNGAN</strong> <d-cite key="miyato2018spectral"></d-cite> Force 1-Lipschitz continuity by spectral normalization of critic‚Äôs layers</li>
</ul>

\[\bar W_{SN} (W) = \frac W {\sigma(W)}\]

<ul>
  <li><strong>LOGAN</strong> <d-cite key="wu2020logan"></d-cite> More gradient flow to generator by making a latent gradient step $z = z + \Delta z$ before passing image to discriminator</li>
</ul>

\[g = \frac{\partial D(G(z))}{\partial z}; \; \; \Delta z = \frac {\alpha} {\beta + \| g \|^2} \cdot g\]

<p>Unfortunately, LOGAN model did not converge in our experiments - it must be a bug in our code, or a conceptual mistake.</p>

<h3 id="evaluation">Evaluation</h3>
<p>We evaluated and compared our models using Inception Score <code class="language-plaintext highlighter-rouge">IS</code> and Frechet Inception distance <code class="language-plaintext highlighter-rouge">FID</code>. Inception Score <d-cite key="salimans2016improved"></d-cite> uses pretrained classificator and measures the variety of generated examples through measuring distribution of labels predicted by pretrained classifier. Frechet inception distance <d-cite key="heusel2018gans"></d-cite> measures this variety by comparing feature distribution extracted by classifier on validation set and generated samples:</p>

\[\| \mu_{real} - \mu_{fake} \|_2^2 + Trace(\Sigma_{real} + \Sigma_{fake} - 2 (\Sigma_1 \Sigma_2)^{0.5})\]

<blockquote>
  <p>FID score between validation and test subsets is 30.56</p>
</blockquote>

<h3 id="results">Results</h3>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/vector_gan/gen.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
    Generated data samples. Note that both vector curves and circles are in use here. Images are rasterized to 64x64 resolution for visualization purposes.
</div>

<p>As for quality scores, neither of the model showed good performance (the scores are far from ground truth FID). Consider the table below.</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>IS</th>
      <th>FID</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>WGAN</td>
      <td>1.935</td>
      <td>94.14</td>
    </tr>
    <tr>
      <td>WGAN-GP</td>
      <td>1.856</td>
      <td>101.7</td>
    </tr>
    <tr>
      <td>SN WGAN-GP</td>
      <td>1.919</td>
      <td>84.54</td>
    </tr>
    <tr>
      <td>LOGAN NGD</td>
      <td>1.11</td>
      <td>208</td>
    </tr>
  </tbody>
</table>

<p>We see that LOGAN is much worse in scores, and indeed the model failed to converge to meaningful results, generating the same repeating pattern. This is known as mode collapse problem. We see no theoretical limitations with using this approach, some hyperparameter tweaking is required to make it work, as we spent a lot of time finding the correct batch size and learning rate to make other models work.</p>

<p>As for Wasserstein GANs, they showed good convergence and results, but results are far from perfect both visually and qualitatively. We did not achieve desired FID score of 30 (as between validation and test subsets). But again, we assume that it is only the matter of longer training.</p>

<blockquote>
  <p>Differentiable rasterization is computationally expensive operation and thus GAN with vector graphics takes approximately 10 times more time to converge. Unfortunately, we could not speed up this process as increasing batch size breaks the training dynamics.</p>
</blockquote>

<h4 id="latent-space-interpolation">Latent space interpolation</h4>

<p>As generator‚Äôs output now has a direct meaning (it is connected to control parameters of underlying primitives), opposed to raster GAN‚Äôs, which generate pixel colors directly, we see extracting meaningful directions in a latent space as promising direction of future research.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/vector_gan/inter1.png" data-zoomable="" />
    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/vector_gan/inter2.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
    Latent space interpolation examples.
</div>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2021 Ivan  Puhachov.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
    
    
  </div>
</footer>



  </body>

  <d-bibliography src="/assets/bibliography/2021-vectorgan.bib">
  </d-bibliography>

  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

</html>
